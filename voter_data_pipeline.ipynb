{"cells":[{"cell_type":"code","execution_count":3,"id":"232b89b3-d16e-4873-bbf1-4079a805f442","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","24/03/17 23:25:52 INFO SparkEnv: Registering MapOutputTracker\n","24/03/17 23:25:52 INFO SparkEnv: Registering BlockManagerMaster\n","24/03/17 23:25:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n","24/03/17 23:25:52 INFO SparkEnv: Registering OutputCommitCoordinator\n"]}],"source":["# Create Spark Session\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession \\\n","        .builder \\\n","        .appName(\"Read Voter File Data\") \\\n","        .getOrCreate()"]},{"cell_type":"code","execution_count":5,"id":"56aaf94d-ad74-4f31-91dc-08aea88d6eb8","metadata":{},"outputs":[],"source":["\"\"\" Use these functions to [read/write] [parquet files/data frames] [from/to] Google Cloud\"\"\"\n","\n","from pyspark.sql import SparkSession\n","\n","def read_parquet_file(spark_session, file_path):\n","    \"\"\"\n","    Reads a Parquet file and returns a Spark DataFrame.\n","    \n","    Parameters:\n","    spark_session (SparkSession): An active SparkSession.\n","    file_path (str): The path to the Parquet file.\n","\n","    Returns:\n","    DataFrame: A Spark DataFrame containing the data from the Parquet file.\n","    \"\"\"\n","\n","    # Read the Parquet file\n","    df = (\n","        spark_session.read\n","        .format(\"parquet\")\n","        .option(\"header\", \"true\")\n","        .option(\"inferSchema\", \"true\")\n","        .load(file_path)\n","    )\n","\n","    return df\n","\n","\n","def write_df_to_gcs_parquet(spark_session, df, bucket_name, file_path):\n","    \"\"\"\n","    Writes a Spark DataFrame to a Google Cloud Storage bucket as a Parquet file.\n","    \n","    Parameters:\n","    spark_session (SparkSession): An active SparkSession.\n","    df (DataFrame): The Spark DataFrame to write.\n","    bucket_name (str): The name of the Google Cloud Storage bucket.\n","    file_path (str): The file path within the bucket where the Parquet file will be saved.\n","    \"\"\"\n","    \n","    # Define the GCS path\n","    gcs_path = f\"gs://{bucket_name}/data_cleaned/{file_path}\"\n","\n","    # Write the DataFrame as a Parquet file to GCS\n","    df.write.parquet(gcs_path, mode='overwrite')\n","    \n","\n","def list_content(bucket_name):\n","    \"\"\"\n","    Lists all the blobs in the bucket.\n","    \n","    Parameters: \n","    bucket_name (str): The name of the Google Cloud Storage bucket. \n","    \"\"\"\n","    storage_client = storage.Client()\n","    content = storage_client.list_blobs(bucket_name)\n","    \n","    for file in content:\n","        print(file.name)"]},{"cell_type":"code","execution_count":null,"id":"bee09439-0249-45ee-a953-38d4d6229d0f","metadata":{},"outputs":[],"source":["# global variables \n","class_bucket_name = \"winter-2024-voter-file\"\n","local_bucket_name = \"pstat135-final-project1\"\n","class_folder_name = \"VM2Uniform\"  \n","\n","# Use the sample_parquet files and the corresponding dataset to test your code before using the actual dataset\n","sample_parquet_files = ['VM2Uniform--AK--2021-02-03', 'VM2Uniform--AL--2021-02-04', 'VM2Uniform--AR--2021-03-16']"]},{"cell_type":"code","execution_count":null,"id":"5413d558-9899-4caf-91e5-8e61ab0d8f20","metadata":{},"outputs":[],"source":["from google.cloud import storage\n","\n","def list_filtered_blobs(bucket_name, folder_name):\n","    \"\"\"Lists all the blobs in a specific folder of the bucket that end with '_SUCCESS'.\"\"\"\n","    storage_client = storage.Client()\n","    prefix = folder_name + '/'\n","    filtered_blobs = []\n","\n","    blobs = storage_client.list_blobs(bucket_name, prefix=prefix)\n","    for blob in blobs:\n","        if blob.name.endswith(\"_SUCCESS\"):\n","            # Remove '_SUCCESS' from the file name\n","            replaced_name = blob.name.replace('_SUCCESS', '')\n","            \n","            split_replaced_name = replaced_name.split('/')\n","            \n","            cleaned_name = split_replaced_name[1]\n","            \n","            if cleaned_name not in filtered_blobs:\n","                filtered_blobs.append(cleaned_name)\n","\n","    return filtered_blobs\n","\n","def aggregate_dataset(files):\n","    dataframes = []\n","\n","    for file in files:\n","        df = read_parquet_file(spark, f\"gs://winter-2024-voter-file/VM2Uniform/{file}\")\n","        subset_df = df.filter((df.Voters_Age >= 18) & (df.Voters_Age <= 29))\n","        sampled_df = subset_df.sample(False, 0.1)  # False for no replacement, 0.1 for 10%\n","        dataframes.append(sampled_df)\n","\n","    aggregate_df = dataframes[0]\n","    for dataframe in dataframes[1:]:\n","        aggregate_df = aggregate_df.union(dataframe)\n","        \n","    return aggregate_df"]},{"cell_type":"code","execution_count":null,"id":"2c40e98f-fe03-49f1-8a72-6ba3f43b4e69","metadata":{},"outputs":[],"source":["success_files = list_filtered_blobs(class_bucket_name, class_folder_name)\n","states = [file.split('--')[1] for file in success_files]"]},{"cell_type":"code","execution_count":null,"id":"0eb9d2ec-9a0d-4c6c-9e81-b5885508180f","metadata":{},"outputs":[],"source":["print(success_files)"]},{"cell_type":"code","execution_count":null,"id":"398b8feb-9fe8-46f5-81fc-b80059f903c7","metadata":{},"outputs":[],"source":["print(states)"]},{"cell_type":"code","execution_count":null,"id":"a0ef2da0-f60c-480b-a313-c44ba8de6317","metadata":{},"outputs":[],"source":["combined_df = aggregate_dataset(success_files)"]},{"cell_type":"code","execution_count":null,"id":"b28f9844-58a6-429f-b915-378946290fa8","metadata":{},"outputs":[],"source":["combined_df.count()"]},{"cell_type":"code","execution_count":null,"id":"90ce0999-f2cd-4342-b31a-3d00ead8acef","metadata":{},"outputs":[],"source":["final_df = combined_df.select(\n","        \"Voters_FirstName\", \n","        \"Voters_LastName\",\n","        \"LALVOTERID\",\n","        \"Voters_Age\",\n","        \"Voters_Gender\",\n","        \"General_2020\",\n","        \"Primary_2020\", \n","        \"Ethnic_Description\",\n","        \"PresidentialPrimary_2020\",\n","        \"EthnicGroups_EthnicGroup1Desc\",\n","        \"Voters_StateVoterID\",\n","        \"CommercialData_Education\",\n","        \"CommercialData_EstHomeValue\",\n","        \"CommercialData_EstimatedHHIncome\",\n",")"]},{"cell_type":"code","execution_count":null,"id":"66a1d0c2-f68d-477a-8e92-2477497f78c4","metadata":{},"outputs":[],"source":["write_df_to_gcs_parquet(spark, final_df, local_bucket_name, \"dataset_young_demographic\")"]},{"cell_type":"code","execution_count":null,"id":"cc35490b-5ca1-4ad7-b5b7-e33285e9c412","metadata":{},"outputs":[],"source":["final_df.select(\"CommercialData_EstHomeValue\").show(truncate=False)"]},{"cell_type":"code","execution_count":null,"id":"a615e121-50fd-47b7-941e-17a9df4e7fa4","metadata":{},"outputs":[],"source":["print(type(final_df))"]},{"cell_type":"code","execution_count":null,"id":"1cb52649-25aa-4e43-9b6f-f39c3bd57afb","metadata":{},"outputs":[],"source":["test_df = aggregate_dataset(sample_parquet_files)"]},{"cell_type":"code","execution_count":null,"id":"ac41099f-019d-47bc-9710-46b7be5ffb88","metadata":{},"outputs":[],"source":["test_df.count()"]},{"cell_type":"code","execution_count":null,"id":"1f3793fd-b532-4d44-924f-361dae1838a3","metadata":{},"outputs":[],"source":["from pyspark.sql.functions import col, avg\n","\n","numerical_df = test_df.withColumn(\"CommercialData_EstHomeValue_in_Dollars\", col(\"CommercialData_EstHomeValue\").cast(\"int\")) # or \"double\" for floating-point numbers\n","\n","numerical_df.select(\"CommercialData_EstHomeValue_in_Dollars\").dtypes"]},{"cell_type":"code","execution_count":null,"id":"a6090b84-ebf7-4b13-b607-b113cfa290bb","metadata":{},"outputs":[],"source":["test_df.select(\"CommercialData_EstHomeValue\").dtypes"]},{"cell_type":"code","execution_count":null,"id":"6104df62-c27f-49c4-b530-b6641336cc5e","metadata":{},"outputs":[],"source":["average_value = numerical_df.select(avg(\"CommercialData_EstHomeValue_in_Dollars\")).first()[0]"]},{"cell_type":"code","execution_count":null,"id":"04f51d5c-3298-46a2-89ef-f4e9e94d3863","metadata":{},"outputs":[],"source":["print(average_value)"]},{"cell_type":"code","execution_count":null,"id":"ee61b47e-57da-48a9-99bc-c361ae964d77","metadata":{},"outputs":[],"source":["numerical_df.select(\"CommercialData_EstHomeValue\", \"CommercialData_EstHomeValue_in_Dollars\").show(truncate=False)"]},{"cell_type":"code","execution_count":null,"id":"aca78dda-f881-4187-a91d-638ef2e1fc0b","metadata":{},"outputs":[],"source":["from pyspark.sql.functions import regexp_replace\n","df_with_numerical = df.withColumn(\"numerical_column\", regexp_replace(\"your_column_name\", \"\\\\$\", \"\").cast(FloatType()))"]},{"cell_type":"code","execution_count":null,"id":"bcad0e96-93ed-4552-b1a0-7f8ae527cf83","metadata":{},"outputs":[],"source":["from pyspark.sql.functions import regexp_replace\n","numerical_df_select = numerical_df.withColumn(\"CommercialData_EstHomeValue_in_Dollars\", regexp_replace(\"CommercialData_EstHomeValue\", \"\\\\$\", \"\").cast(\"int\"))"]},{"cell_type":"code","execution_count":null,"id":"60a1bb4a-a3e5-47e6-916e-f1373bad102e","metadata":{},"outputs":[],"source":["numerical_df_select.select(\"CommercialData_EstHomeValue\", \"CommercialData_EstHomeValue_in_Dollars\").show(truncate=False)"]},{"cell_type":"code","execution_count":null,"id":"24f9907d-1f7f-4d4e-b28c-e37c1b392225","metadata":{},"outputs":[],"source":["average_value = numerical_df_select.select(avg(\"CommercialData_EstHomeValue_in_Dollars\")).first()[0]"]},{"cell_type":"code","execution_count":null,"id":"76402078-2ac1-47f1-be4c-55068285c1b4","metadata":{},"outputs":[],"source":["print(average_value)"]},{"cell_type":"code","execution_count":null,"id":"3e1745b2-207a-42e0-a887-5c1929ac7f57","metadata":{},"outputs":[],"source":["pandas_df = numerical_df_select.select(\"CommercialData_EstHomeValue_in_Dollars\").toPandas()"]},{"cell_type":"code","execution_count":null,"id":"40d977b5-0c00-4727-ae13-d92ddaafd5aa","metadata":{},"outputs":[],"source":["pandas_df.median()"]},{"cell_type":"code","execution_count":null,"id":"2dc51029-00bd-4fd2-926f-5f9dd45acd20","metadata":{},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Assuming 'pandas_df' is your Pandas DataFrame and 'your_column_name' is the column you want to plot\n","plt.figure(figsize=(10, 6))\n","sns.histplot(pandas_df['CommercialData_EstHomeValue_in_Dollars'], kde=True, stat=\"percent\")\n","\n","\n","plt.xlim([0, 1000000])\n","plt.title('Distribution of Your CommercialData_EstHomeValue_in_Dollars')\n","plt.xlabel('Value')\n","plt.ylabel('Frequency')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"f7596650-aeba-4300-9b71-abbd09c88284","metadata":{},"outputs":[],"source":["final_df.select(\"CommercialData_EstimatedHHIncome\").show(truncate=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}
